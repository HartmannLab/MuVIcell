{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MuVIcell Tutorial: Multi-View Integration for Sample-Aggregated Single-Cell Data\n",
    "\n",
    "This notebook demonstrates how to use the MuVIcell package for multi-view integration and analysis of sample-aggregated single-cell data using MuVI (Multi-View Integration).\n",
    "\n",
    "## Overview\n",
    "\n",
    "MuVIcell provides a streamlined workflow for:\n",
    "1. **Generating/Loading** multi-view data in muon format (samples x features)\n",
    "2. **Preprocessing** data for MuVI analysis\n",
    "3. **Running MuVI** to identify latent factors using `muvi.tl.from_mdata`\n",
    "4. **Analyzing** and interpreting factors\n",
    "5. **Visualizing** results\n",
    "\n",
    "Note: Each row represents a **sample** (not individual cells) and views contain **cell type aggregated data per sample**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import muvicell\n",
    "muvicell.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensordict\n",
    "tensordict.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import muon as mu\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from plotnine import *\n",
    "import scanpy as sc\n",
    "\n",
    "# Import muvicell modules\n",
    "from muvicell import synthetic, preprocessing, analysis, visualization\n",
    "\n",
    "# Import MuVI directly to show compatibility\n",
    "import muvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "try:\n",
    "    device = f\"cuda:{muvi.get_free_gpu_idx()}\"\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Multi-View Data\n",
    "\n",
    "Generate synthetic data with 3 views (5, 10, 15 features) and 200 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic multi-view data (3 views matching 3 true factors)\n",
    "mdata = synthetic.generate_synthetic_data(\n",
    "    n_samples=200,\n",
    "    view_configs={\n",
    "        'Cell Type 1': {'n_vars': 5, 'sparsity': 0.15},\n",
    "        'Cell Type 2': {'n_vars': 10, 'sparsity': 0.25},\n",
    "        'Cell Type 3': {'n_vars': 15, 'sparsity': 0.35}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Generated synthetic data:\")\n",
    "print(f\"- Samples: {mdata.n_obs}\")\n",
    "print(f\"- Views: {len(mdata.mod)} ({', '.join([f'{k}: {v.n_vars} features' for k, v in mdata.mod.items()])})\")\n",
    "print(f\"- Total features: {sum(v.n_vars for v in mdata.mod.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add Latent Factor Structure\n",
    "\n",
    "Add realistic latent factor structure to the synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add latent structure with 3 factors (matching n_true_factors)\n",
    "mdata_structured = synthetic.add_latent_structure(\n",
    "    mdata, \n",
    "    n_latent_factors = 3,\n",
    "    factor_variance = [0.5, 0.4, 0.3],\n",
    "    structure_strength = 1.0,\n",
    "    baseline_strength = 0.6\n",
    ")\n",
    "\n",
    "print(f\"Sample metadata columns: {list(mdata_structured.obs.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod in mdata_structured.mod:\n",
    "    # Highly variable features can be used if there's enough of them\n",
    "    sc.pp.pca(mdata_structured[mod], \n",
    "              use_highly_variable=False)\n",
    "    sc.pp.neighbors(mdata_structured[mod])\n",
    "\n",
    "mu.pp.neighbors(mdata_structured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy factor loadings to single view\n",
    "for var in ['sim_factor_1', 'sim_factor_2', 'sim_factor_3']:\n",
    "    mdata_structured[mod].obs[var] = mdata_structured.obs[var]\n",
    "\n",
    "sc.tl.umap(mdata_structured[mod])\n",
    "sc.pl.umap(mdata_structured[mod], color=['batch', \n",
    "                                        'sim_factor_1',\n",
    "                                        'sim_factor_2',\n",
    "                                        'sim_factor_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.tl.umap(mdata_structured)\n",
    "mu.pl.umap(mdata_structured, wspace=0.3, color=['batch', \n",
    "                                                'sim_factor_1',\n",
    "                                                'sim_factor_2',\n",
    "                                                'sim_factor_3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these parameters, we create 3 latent factors with specified variances, a strong structured signal, and a moderate baseline signal across all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say an exposure variable is highly correlated with factor 1\n",
    "mdata_structured.obs['exposure'] = [np.random.choice([\"Hi\", \"Medium\", \"Low\"], p = [0.7,0.2,0.1]) if x > 1 else\n",
    "                                    np.random.choice([\"Hi\", \"Medium\", \"Low\"], p = [0.1,0.7,0.2]) if x > 0 else\n",
    "                                    np.random.choice([\"Hi\", \"Medium\", \"Low\"], p = [0.1,0.2,0.7]) \n",
    "                                    for x in mdata_structured.obs['sim_factor_1']]\n",
    "mdata_structured.obs['exposure'] = pd.Categorical(mdata_structured.obs['exposure'], \n",
    "                                                  categories=[\"Low\", \"Medium\", \"Hi\"], \n",
    "                                                  ordered=True)\n",
    "mdata_structured.obs['exposure'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess Data for MuVI\n",
    "\n",
    "Apply preprocessing pipeline (optimized for synthetic data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess for MuVI analysis\n",
    "mdata_processed = preprocessing.preprocess_for_muvi(\n",
    "    mdata_structured,\n",
    "    filter_cells=False,  # Don't filter synthetic data\n",
    "    filter_genes=False,  # Don't filter synthetic data\n",
    "    normalize=True,\n",
    "    find_hvg=False,      # Skip HVG for synthetic data\n",
    "    subset_hvg=False\n",
    ")\n",
    "\n",
    "print(f\"Preprocessed data shape: {mdata_processed.shape}\")\n",
    "print(\"Data ready for MuVI analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run MuVI Analysis\n",
    "\n",
    "Run MuVI using the exact same API as the original analysis, with 3 factors to match our synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MuVI using the standard API\n",
    "model = muvi.tl.from_mdata(\n",
    "    mdata_processed,\n",
    "    n_factors=3,\n",
    "    nmf=False,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit()\n",
    "\n",
    "print(f\"MuVI model fitted with {model.n_factors} factors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display variance explained\n",
    "r2_pool = []\n",
    "for vn in model.get_factor_loadings().keys():\n",
    "    rec = model.get_factor_scores() @ model.get_factor_loadings()[vn]\n",
    "    r2 = pd.DataFrame({'x': mdata_processed[vn].X.flatten(), \n",
    "                       'y': rec.flatten()}).corr()\n",
    "    r2_pool.append(r2.iloc[0,1])\n",
    "print(f\"Macro R2: {np.mean(np.square(r2_pool))}\")\n",
    "\n",
    "# Check factor scores\n",
    "factor_scores = model.get_factor_scores()\n",
    "print(f\"Factor scores shape: {factor_scores.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Bonus) Confirm the factors recovered match the simulation parameters\n",
    "This is only possible here since we generated the data ourselves, and cannot be done in real applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_df = pd.DataFrame(\n",
    "    np.hstack([mdata_processed.obsm['true_factors'], factor_scores]),\n",
    "    columns=[f\"True_Factor_{i+1}\" for i in range(3)] + [f\"MuVI_Factor_{i+1}\" for i in range(model.n_factors)]\n",
    ")\n",
    "corr_factors = factors_df.corr(method='spearman')\n",
    "corr_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that many of the true factors are well recovered, with high positive/negative correlation (> 0.5) between true and inferred factor scores. Some effects are split across multiple inferred factors, as different combinations of factors can explain the variance if they are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Characterize Factors\n",
    "Identify top genes contributing to each factor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MuVI reusable utilities: info + plot pairs\n",
    "# =============================================================================\n",
    "from typing import Dict, List, Optional, Sequence, Tuple, Callable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from plotnine import (\n",
    "    ggplot, aes, geom_col, geom_rect, geom_text, geom_tile, geom_violin, geom_path,\n",
    "    scale_fill_gradientn, scale_fill_gradient2, scale_fill_manual,\n",
    "    scale_x_continuous, scale_y_continuous,\n",
    "    theme_classic, theme, element_text, coord_fixed, coord_flip, coord_equal,\n",
    "    labs, ggtitle, guides\n",
    ")\n",
    "from plotnine import ggsave\n",
    "\n",
    "# If you use liana, keep the import; the code below does not require it.\n",
    "# import liana as li\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Helpers\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def _to_factor_labels(names: Sequence[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Map ['factor_0','factor_1', ...] to ['Factor 1','Factor 2', ...] if pattern matches,\n",
    "    otherwise return names unchanged.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for n in names:\n",
    "        try:\n",
    "            if isinstance(n, str) and \"factor_\" in n:\n",
    "                idx = int(n.split(\"_\")[1])\n",
    "                out.append(f\"Factor {idx+1}\")\n",
    "            else:\n",
    "                out.append(n)\n",
    "        except Exception:\n",
    "            out.append(n)\n",
    "    return out\n",
    "\n",
    "def _rename_factor_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Rename factor_* columns to human readable Factor i.\"\"\"\n",
    "    renamed = df.copy()\n",
    "    newcols = []\n",
    "    for c in renamed.columns:\n",
    "        if isinstance(c, str) and c.startswith(\"factor_\"):\n",
    "            try:\n",
    "                newcols.append(f\"Factor {int(c.split('_')[1]) + 1}\")\n",
    "            except Exception:\n",
    "                newcols.append(c)\n",
    "        else:\n",
    "            newcols.append(c)\n",
    "    renamed.columns = newcols\n",
    "    return renamed\n",
    "\n",
    "def _ggsave_if(p, save_path: Optional[str], width: float = 6, height: float = 4, dpi: int = 300, verbose: bool = False):\n",
    "    if save_path:\n",
    "        ggsave(save_path, plot=p, width=width, height=height, dpi=dpi, verbose=verbose)\n",
    "\n",
    "def _nan_pearsonr(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    if m.sum() < 3:\n",
    "        return np.nan\n",
    "    return np.corrcoef(x[m], y[m])[0, 1]\n",
    "\n",
    "def _factor_names_from_model(model) -> List[str]:\n",
    "    # Try to pull names from factor scores df if available\n",
    "    try:\n",
    "        fs = model.get_factor_scores(as_df=True)\n",
    "        cols = list(fs.columns)\n",
    "        return cols\n",
    "    except Exception:\n",
    "        # Fallback to factor_0..factor_{k-1}\n",
    "        try:\n",
    "            k = model.n_factors\n",
    "        except Exception:\n",
    "            k = 10\n",
    "        return [f\"factor_{i}\" for i in range(k)]\n",
    "\n",
    "def _view_names(model, mdata) -> List[str]:\n",
    "    for attr in [\"view_names\", \"views\", \"modalities\"]:\n",
    "        if hasattr(model, attr):\n",
    "            v = getattr(model, attr)\n",
    "            return list(v)\n",
    "    return list(mdata.mod.keys())\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Reconstruction R2 per view\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def muvi_reconstruction_info(model, mdata, views: Optional[Sequence[str]] = None, verbosity: int = 1) -> dict:\n",
    "    \"\"\"\n",
    "    Compute R and R2 between original X and reconstructed X = scores @ loadings, per view.\n",
    "    Returns dict with keys:\n",
    "      'by_view': DataFrame[view, R, R2]\n",
    "      'macro': {'R': macro_R, 'R2': macro_R2}\n",
    "    \"\"\"\n",
    "    if views is None:\n",
    "        views = _view_names(model, mdata)\n",
    "\n",
    "    # scores: (n_obs x n_factors)\n",
    "    scores = model.get_factor_scores()\n",
    "    if isinstance(scores, pd.DataFrame):\n",
    "        scores = scores.to_numpy()\n",
    "\n",
    "    per_view = []\n",
    "    loadings = model.get_factor_loadings()  # dict or similar keyed by view\n",
    "    for v in views:\n",
    "        L = loadings[v]  # shape: n_factors x n_features_v\n",
    "        # rebuild\n",
    "        rec = scores @ L  # (n_obs x n_features_v)\n",
    "        X = mdata[v].X  # original (n_obs x n_features_v)\n",
    "        r = _nan_pearsonr(np.asarray(X).ravel(), np.asarray(rec).ravel())\n",
    "        per_view.append({\"view\": v, \"R\": r, \"R2\": None if pd.isna(r) else r * r})\n",
    "\n",
    "    df = pd.DataFrame(per_view)\n",
    "    macro_R = df[\"R\"].mean(skipna=True)\n",
    "    macro_R2 = df[\"R2\"].mean(skipna=True)\n",
    "\n",
    "    if verbosity:\n",
    "        print(\"Reconstruction macro R:\", np.round(macro_R, 3))\n",
    "        print(\"Reconstruction macro R2:\", np.round(macro_R2, 3))\n",
    "        print(df.sort_values(\"R2\", ascending=False).to_string(index=False))\n",
    "\n",
    "    return {\"by_view\": df, \"macro\": {\"R\": macro_R, \"R2\": macro_R2}}\n",
    "\n",
    "def muvi_reconstruction_plot(stats_df: pd.DataFrame,\n",
    "                             title: str = \"Reconstruction R2 by view\",\n",
    "                             save_path: Optional[str] = None,\n",
    "                             width: float = 6, height: float = 4, dpi: int = 300):\n",
    "    \"\"\"\n",
    "    Bar plot of R2 per view. Returns the ggplot object.\n",
    "    \"\"\"\n",
    "    p = (\n",
    "        ggplot(stats_df, aes(x=\"view\", y=\"R2\"))\n",
    "        + geom_col()\n",
    "        + theme_classic()\n",
    "        + theme(axis_text_x=element_text(angle=45, hjust=1))\n",
    "        + labs(title=title, x=\"View\", y=\"R2\")\n",
    "    )\n",
    "    _ggsave_if(p, save_path, width, height, dpi)\n",
    "    return p\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Variance explained by factors per view with marginal sums\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def muvi_variance_by_view_info(model, view_name_transform: Optional[Callable[[str], str]] = None,\n",
    "                               verbosity: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Long tidy DataFrame with columns [Factor, View, Variance].\n",
    "    Uses muvi.tl.variance_explained(model)[1].\n",
    "    \"\"\"\n",
    "    vexp = __import__(\"muvi\").tl.variance_explained(model)[1]  # DataFrame factors x views\n",
    "    df = vexp.copy()\n",
    "    df.index.name = \"Factor\"\n",
    "    df = df.reset_index().melt(id_vars=\"Factor\", var_name=\"View\", value_name=\"Variance\")\n",
    "\n",
    "    # Human friendly factor labels where possible\n",
    "    df[\"Factor\"] = _to_factor_labels(df[\"Factor\"])\n",
    "    # Optional view transformation\n",
    "    if view_name_transform is not None:\n",
    "        df[\"View\"] = df[\"View\"].map(view_name_transform)\n",
    "\n",
    "    # Ordered category by factor index if parsable\n",
    "    facs = pd.unique(df[\"Factor\"])\n",
    "    df[\"Factor\"] = pd.Categorical(df[\"Factor\"], categories=facs, ordered=True)\n",
    "\n",
    "    if verbosity:\n",
    "        print(df.head().to_string(index=False))\n",
    "    return df\n",
    "\n",
    "def muvi_variance_by_view_plot(df: pd.DataFrame,\n",
    "                               subtitle: Optional[str] = None,\n",
    "                               save_path: Optional[str] = None,\n",
    "                               width: float = 6, height: float = 5, dpi: int = 300):\n",
    "    \"\"\"\n",
    "    Heatmap with marginal sums. Returns ggplot.\n",
    "    \"\"\"\n",
    "    # Compute marginals\n",
    "    row_sums = df.groupby(\"View\", as_index=False)[\"Variance\"].sum()\n",
    "    row_sums[\"Factor\"] = \"Sum\"\n",
    "\n",
    "    col_sums = df.groupby(\"Factor\", as_index=False)[\"Variance\"].sum()\n",
    "    col_sums[\"View\"] = \"Sum\"\n",
    "\n",
    "    # sort views descending by total variance\n",
    "    sorted_views = row_sums.sort_values(\"Variance\", ascending=False)[\"View\"].tolist()\n",
    "\n",
    "    # Prepare extended frame with 'Sum' row and col\n",
    "    factor_levels = list(df[\"Factor\"].cat.categories if isinstance(df[\"Factor\"].dtype, pd.CategoricalDtype) else df[\"Factor\"].unique())\n",
    "    factor_levels = list(factor_levels) + [\"Sum\"]\n",
    "    view_levels = sorted_views + [\"Sum\"]\n",
    "\n",
    "    dfm = pd.concat([df, row_sums, col_sums], ignore_index=True)\n",
    "    dfm[\"Factor\"] = pd.Categorical(dfm[\"Factor\"], categories=factor_levels, ordered=True)\n",
    "    dfm[\"View\"] = pd.Categorical(dfm[\"View\"], categories=view_levels, ordered=True)\n",
    "\n",
    "    # Split for plotting\n",
    "    main = dfm[(dfm[\"Factor\"] != \"Sum\") & (dfm[\"View\"] != \"Sum\")].copy()\n",
    "    rowb = dfm[(dfm[\"Factor\"] == \"Sum\") & (dfm[\"View\"] != \"Sum\")].copy()\n",
    "    colb = dfm[(dfm[\"View\"] == \"Sum\") & (dfm[\"Factor\"] != \"Sum\")].copy()\n",
    "\n",
    "    # Normalize bar lengths\n",
    "    rowb[\"bar_length\"] = rowb[\"Variance\"] / rowb[\"Variance\"].max()\n",
    "    colb[\"bar_length\"] = colb[\"Variance\"] / colb[\"Variance\"].max()\n",
    "    rowb[\"Variance_label\"] = rowb[\"Variance\"].round(2).astype(str)\n",
    "    colb[\"Variance_label\"] = colb[\"Variance\"].round(2).astype(str)\n",
    "\n",
    "    # Positions\n",
    "    fac_no_sum = [x for x in factor_levels if x != \"Sum\"]\n",
    "    view_no_sum = [x for x in view_levels if x != \"Sum\"]\n",
    "    fpos = {k: i for i, k in enumerate(fac_no_sum)}\n",
    "    vpos = {k: i for i, k in enumerate(view_no_sum)}\n",
    "\n",
    "    main[\"x\"] = main[\"Factor\"].map(fpos)\n",
    "    main[\"y\"] = main[\"View\"].map(vpos)\n",
    "    colb[\"x\"] = colb[\"Factor\"].map(fpos)\n",
    "    rowb[\"y\"] = rowb[\"View\"].map(vpos)\n",
    "\n",
    "    # tile coords\n",
    "    main[\"xmin\"] = main[\"x\"] - 0.5\n",
    "    main[\"xmax\"] = main[\"x\"] + 0.5\n",
    "    main[\"ymin\"] = main[\"y\"] - 0.5\n",
    "    main[\"ymax\"] = main[\"y\"] + 0.5\n",
    "\n",
    "    # top bars\n",
    "    colb[\"xmin\"] = colb[\"x\"] - 0.5\n",
    "    colb[\"xmax\"] = colb[\"x\"] + 0.5\n",
    "    colb[\"ymin\"] = len(view_no_sum) - 0.5\n",
    "    colb[\"ymax\"] = colb[\"ymin\"] + colb[\"bar_length\"]\n",
    "\n",
    "    # right bars\n",
    "    rowb[\"ymin\"] = rowb[\"y\"] - 0.5\n",
    "    rowb[\"ymax\"] = rowb[\"y\"] + 0.5\n",
    "    rowb[\"xmin\"] = len(fac_no_sum) - 0.5\n",
    "    rowb[\"xmax\"] = rowb[\"xmin\"] + rowb[\"bar_length\"]\n",
    "\n",
    "    p = (\n",
    "        ggplot()\n",
    "        + geom_rect(main, aes(xmin=\"xmin\", xmax=\"xmax\", ymin=\"ymin\", ymax=\"ymax\", fill=\"Variance\"))\n",
    "        + geom_rect(colb, aes(xmin=\"xmin\", xmax=\"xmax\", ymin=\"ymin\", ymax=\"ymax\"), fill=\"#acabab\")\n",
    "        + geom_text(colb, aes(x=\"x\", y=main[\"ymax\"].max() + 0.2, label=\"Variance_label\"), va=\"bottom\", size=8)\n",
    "        + geom_rect(rowb, aes(xmin=\"xmin\", xmax=\"xmax\", ymin=\"ymin\", ymax=\"ymax\"), fill=\"#acabab\")\n",
    "        + geom_text(rowb, aes(x=main[\"xmax\"].max() + 0.2, y=\"y\", label=\"Variance_label\"), ha=\"left\", size=8)\n",
    "        + scale_fill_gradientn(colors=[\"#EFF822\", \"#CC4977\", \"#0F0782\"])\n",
    "        + scale_x_continuous(breaks=list(range(len(fac_no_sum))), labels=fac_no_sum)\n",
    "        + scale_y_continuous(breaks=list(range(len(view_no_sum))), labels=view_no_sum)\n",
    "        + theme_classic()\n",
    "        + theme(axis_text_x=element_text(angle=45, hjust=1))\n",
    "        + labs(title=\"Variance explained by MuVI factors\", subtitle=subtitle, x=\"Factor\", y=\"View\")\n",
    "    )\n",
    "    _ggsave_if(p, save_path, width, height, dpi)\n",
    "    return p\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Feature class vs factor variance explained (aggregated across views)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def muvi_featureclass_variance_info(model, mdata,\n",
    "                                    feature_type_map: Dict[str, List[str]],\n",
    "                                    aggregator: str = \"median\",\n",
    "                                    verbosity: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute variance explained per factor for each feature class across views.\n",
    "    feature_type_map: {'Class name': [feature1, feature2, ...]}\n",
    "    aggregator: 'median' or 'mean' across views.\n",
    "    Returns long DataFrame [Factor, Feature_type, Variance].\n",
    "    \"\"\"\n",
    "    assert aggregator in {\"median\", \"mean\"}\n",
    "    views = _view_names(model, mdata)\n",
    "    import muvi as _muvi  # local import to avoid collisions\n",
    "\n",
    "    rows = []\n",
    "    for cls, feats in feature_type_map.items():\n",
    "        per_view_vals = []\n",
    "        for v in views:\n",
    "            feats_in_view = [f for f in feats if f in list(mdata[v].var_names)]\n",
    "            if len(feats_in_view) == 0:\n",
    "                continue\n",
    "            # r2[1] is per-factor variance for the selected features in this view\n",
    "            r2 = _muvi.tl.variance_explained(model, view_idx=v, feature_idx=feats_in_view, cache=False, sort=False)[1]\n",
    "            per_view_vals.append(r2.values.reshape(-1, 1))  # factors x 1\n",
    "\n",
    "        if len(per_view_vals) == 0:\n",
    "            continue\n",
    "\n",
    "        A = np.hstack(per_view_vals)  # factors x n_views_present\n",
    "        agg = np.median(A, axis=1) if aggregator == \"median\" else np.mean(A, axis=1)\n",
    "        # Build factor names from r2.index\n",
    "        factor_labels = _to_factor_labels(list(r2.index))\n",
    "        rows.extend([{\"Factor\": f, \"Feature_type\": cls, \"Variance\": val} for f, val in zip(factor_labels, agg)])\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    out[\"Factor\"] = pd.Categorical(out[\"Factor\"], categories=_to_factor_labels(sorted(set(x for x in out[\"Factor\"]), key=lambda s: int(str(s).split()[-1]) if str(s).startswith(\"Factor\") else 0)), ordered=True)\n",
    "\n",
    "    if verbosity:\n",
    "        print(out.head().to_string(index=False))\n",
    "    return out\n",
    "\n",
    "def muvi_featureclass_variance_plot(df: pd.DataFrame,\n",
    "                                    save_path: Optional[str] = None,\n",
    "                                    width: float = 5, height: float = 5, dpi: int = 300):\n",
    "    \"\"\"\n",
    "    Heatmap with marginal sums for feature class vs factor. Returns ggplot.\n",
    "    \"\"\"\n",
    "    # marginals\n",
    "    row_sums = df.groupby(\"Feature_type\", as_index=False)[\"Variance\"].sum()\n",
    "    row_sums[\"Factor\"] = \"Sum\"\n",
    "    col_sums = df.groupby(\"Factor\", as_index=False)[\"Variance\"].sum()\n",
    "    col_sums[\"Feature_type\"] = \"Sum\"\n",
    "\n",
    "    # order feature types\n",
    "    sorted_ft = row_sums.sort_values(\"Variance\", ascending=False)[\"Feature_type\"].tolist()\n",
    "\n",
    "    # categories\n",
    "    factor_levels = list(pd.unique(df[\"Factor\"])) + [\"Sum\"]\n",
    "    ft_levels = sorted_ft + [\"Sum\"]\n",
    "\n",
    "    dfx = pd.concat([df, row_sums, col_sums], ignore_index=True)\n",
    "    dfx[\"Factor\"] = pd.Categorical(dfx[\"Factor\"], categories=factor_levels, ordered=True)\n",
    "    dfx[\"Feature_type\"] = pd.Categorical(dfx[\"Feature_type\"], categories=ft_levels, ordered=True)\n",
    "\n",
    "    main = dfx[(dfx[\"Factor\"] != \"Sum\") & (dfx[\"Feature_type\"] != \"Sum\")].copy()\n",
    "    rowb = dfx[(dfx[\"Factor\"] == \"Sum\") & (dfx[\"Feature_type\"] != \"Sum\")].copy()\n",
    "    colb = dfx[(dfx[\"Feature_type\"] == \"Sum\") & (dfx[\"Factor\"] != \"Sum\")].copy()\n",
    "\n",
    "    rowb[\"bar_length\"] = rowb[\"Variance\"] / rowb[\"Variance\"].max()\n",
    "    colb[\"bar_length\"] = colb[\"Variance\"] / colb[\"Variance\"].max()\n",
    "    rowb[\"Variance_label\"] = rowb[\"Variance\"].round(2).astype(str)\n",
    "    colb[\"Variance_label\"] = colb[\"Variance\"].round(2).astype(str)\n",
    "\n",
    "    fac_no_sum = [x for x in factor_levels if x != \"Sum\"]\n",
    "    ft_no_sum = [x for x in ft_levels if x != \"Sum\"]\n",
    "    fpos = {k: i for i, k in enumerate(fac_no_sum)}\n",
    "    ftpos = {k: i for i, k in enumerate(ft_no_sum)}\n",
    "\n",
    "    main[\"x\"] = main[\"Factor\"].map(fpos)\n",
    "    main[\"y\"] = main[\"Feature_type\"].map(ftpos)\n",
    "    colb[\"x\"] = colb[\"Factor\"].map(fpos)\n",
    "    rowb[\"y\"] = rowb[\"Feature_type\"].map(ftpos)\n",
    "\n",
    "    main[\"xmin\"] = main[\"x\"] - 0.5\n",
    "    main[\"xmax\"] = main[\"x\"] + 0.5\n",
    "    main[\"ymin\"] = main[\"y\"] - 0.5\n",
    "    main[\"ymax\"] = main[\"y\"] + 0.5\n",
    "\n",
    "    colb[\"xmin\"] = colb[\"x\"] - 0.5\n",
    "    colb[\"xmax\"] = colb[\"x\"] + 0.5\n",
    "    colb[\"ymin\"] = len(ft_no_sum) - 0.5\n",
    "    colb[\"ymax\"] = colb[\"ymin\"] + colb[\"bar_length\"]\n",
    "\n",
    "    rowb[\"ymin\"] = rowb[\"y\"] - 0.5\n",
    "    rowb[\"ymax\"] = rowb[\"y\"] + 0.5\n",
    "    rowb[\"xmin\"] = len(fac_no_sum) - 0.5\n",
    "    rowb[\"xmax\"] = rowb[\"xmin\"] + rowb[\"bar_length\"]\n",
    "\n",
    "    p = (\n",
    "        ggplot()\n",
    "        + geom_rect(main, aes(xmin=\"xmin\", xmax=\"xmax\", ymin=\"ymin\", ymax=\"ymax\", fill=\"Variance\"))\n",
    "        + geom_rect(colb, aes(xmin=\"xmin\", xmax=\"xmax\", ymin=\"ymin\", ymax=\"ymax\"), fill=\"#acabab\")\n",
    "        + geom_text(colb, aes(x=\"x\", y=main[\"ymax\"].max() + 0.2, label=\"Variance_label\"), va=\"bottom\", size=8)\n",
    "        + geom_rect(rowb, aes(xmin=\"xmin\", xmax=\"xmax\", ymin=\"ymin\", ymax=\"ymax\"), fill=\"#acabab\")\n",
    "        + geom_text(rowb, aes(x=main[\"xmax\"].max() + 0.2, y=\"y\", label=\"Variance_label\"), ha=\"left\", size=8)\n",
    "        + scale_fill_gradientn(colors=[\"#EFF822\", \"#CC4977\", \"#0F0782\"])\n",
    "        + scale_x_continuous(breaks=list(range(len(fac_no_sum))), labels=fac_no_sum)\n",
    "        + scale_y_continuous(breaks=list(range(len(ft_no_sum))), labels=ft_no_sum)\n",
    "        + theme_classic()\n",
    "        + theme(axis_text_x=element_text(angle=45, hjust=1))\n",
    "        + labs(title=\"Variance explained by MuVI factors\", x=\"Factor\", y=\"Feature type\")\n",
    "    )\n",
    "    _ggsave_if(p, save_path, width, height, dpi)\n",
    "    return p\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Variable loadings per feature and top features heatmap\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def muvi_variable_loadings_info(model, mdata, verbosity: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a wide DataFrame with rows = variables (feature names), columns = Factor i,\n",
    "    plus a 'view' column with the originating view.\n",
    "    \"\"\"\n",
    "    all_loadings = model.get_factor_loadings(model.view_names, model.factor_names, as_df=True)\n",
    "    chunks = []\n",
    "    for view in _view_names(model, mdata):\n",
    "        # transpose to variables x factors\n",
    "        df_v = all_loadings[view].T.copy()\n",
    "        # Reorder factor columns if factor_0.. present\n",
    "        fcols = [c for c in df_v.columns if isinstance(c, str) and c.startswith(\"factor_\")]\n",
    "        if len(fcols) == df_v.shape[1]:\n",
    "            fcols_sorted = [f\"factor_{i}\" for i in range(len(fcols))]\n",
    "            df_v = df_v.loc[:, fcols_sorted]\n",
    "        df_v[\"view\"] = view\n",
    "        df_v[\"variable\"] = df_v.index\n",
    "        chunks.append(df_v)\n",
    "\n",
    "    var_load = pd.concat(chunks, axis=0, ignore_index=False)\n",
    "    var_load = var_load.rename_axis(\"variable\").reset_index(drop=True)\n",
    "    var_load = _rename_factor_columns(var_load)\n",
    "\n",
    "    if verbosity:\n",
    "        print(var_load.head().to_string(index=False))\n",
    "    return var_load  # columns: Factor i..., view, variable\n",
    "\n",
    "def muvi_plot_top_loadings_heatmap(variable_loadings: pd.DataFrame,\n",
    "                                   factor: str = \"Factor 1\",\n",
    "                                   top_n: int = 30, by_abs: bool = True,\n",
    "                                   save_path: Optional[str] = None,\n",
    "                                   width: float = 5, height: float = 5, dpi: int = 300):\n",
    "    \"\"\"\n",
    "    Tile heatmap of top features across views for a given factor.\n",
    "    \"\"\"\n",
    "    df = variable_loadings.copy()\n",
    "    if factor not in df.columns:\n",
    "        raise ValueError(f\"Factor column not found: {factor}\")\n",
    "    key = df[factor].abs() if by_abs else df[factor]\n",
    "    top_vars = df.assign(score=key).sort_values(\"score\", ascending=False).head(top_n)[\"variable\"].tolist()\n",
    "    plot_df = df[df[\"variable\"].isin(top_vars)][[\"variable\", \"view\", factor]].copy()\n",
    "    p = (\n",
    "        ggplot(plot_df)\n",
    "        + aes(x=\"view\", y=\"variable\", fill=factor)\n",
    "        + geom_tile()\n",
    "        + scale_fill_gradient2(low=\"#1f77b4\", mid=\"lightgray\", high=\"#c20019\", limits=[-1.1, 1.1])\n",
    "        + theme_classic()\n",
    "        + theme(axis_text_x=element_text(angle=45, hjust=1))\n",
    "        + labs(title=factor, x=\"View\", y=\"Feature\", fill=\"Loading\")\n",
    "        + coord_fixed()\n",
    "    )\n",
    "    _ggsave_if(p, save_path, width, height, dpi)\n",
    "    return p\n",
    "\n",
    "def muvi_selected_features_info(variable_loadings: pd.DataFrame,\n",
    "                                selections: Sequence[Tuple[str, str]],\n",
    "                                verbosity: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    selections: list of (feature_name, view) pairs.\n",
    "    Returns long DataFrame with columns [Variable, view, Factor, loading].\n",
    "    \"\"\"\n",
    "    base = variable_loadings.set_index([\"variable\", \"view\"])\n",
    "    # Collect rows present in selections\n",
    "    chosen = []\n",
    "    for ft, view in selections:\n",
    "        if (ft, view) in base.index:\n",
    "            row = base.loc[(ft, view)]\n",
    "            tmp = row.drop(labels=[], errors=\"ignore\")\n",
    "            tmp_df = tmp.dropna().to_frame().T  # include all factor columns\n",
    "            tmp_df[\"variable\"] = ft\n",
    "            tmp_df[\"view\"] = view\n",
    "            chosen.append(tmp_df)\n",
    "    if len(chosen) == 0:\n",
    "        out = pd.DataFrame(columns=[\"Variable\", \"view\", \"Factor\", \"loading\"])\n",
    "    else:\n",
    "        wide = pd.concat(chosen, ignore_index=True)\n",
    "        # gather factors only\n",
    "        factor_cols = [c for c in wide.columns if str(c).startswith(\"Factor \")]\n",
    "        out = wide.melt(id_vars=[\"variable\", \"view\"], value_vars=factor_cols,\n",
    "                        var_name=\"Factor\", value_name=\"loading\").rename(columns={\"variable\": \"Variable\"})\n",
    "    if verbosity:\n",
    "        print(out.head().to_string(index=False))\n",
    "    return out\n",
    "\n",
    "def muvi_selected_features_plot(df_long: pd.DataFrame,\n",
    "                                save_path: Optional[str] = None,\n",
    "                                width: float = 6, height: float = 5, dpi: int = 300):\n",
    "    \"\"\"\n",
    "    Heatmap of selected feature loadings across factors.\n",
    "    \"\"\"\n",
    "    p = (\n",
    "        ggplot(df_long, aes(x=\"Factor\", y=\"Variable\", fill=\"loading\"))\n",
    "        + geom_tile()\n",
    "        + scale_fill_gradient2(low=\"#1f77b4\", mid=\"lightgray\", high=\"#c20019\", limits=[-1.1, 1.1])\n",
    "        + theme_classic()\n",
    "        + theme(axis_text_x=element_text(angle=45, hjust=1), legend_position=\"bottom\")\n",
    "        + labs(title=\"Selected features loadings\", x=\"Factor\", y=\"Feature/view\", fill=\"Loading\")\n",
    "        + coord_fixed()\n",
    "    )\n",
    "    _ggsave_if(p, save_path, width, height, dpi)\n",
    "    return p\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) Factor scores with clinical covariates and tests\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def muvi_factor_scores_info(model, mdata, obs_keys: Optional[Sequence[str]] = None,\n",
    "                            verbosity: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return factor scores as a DataFrame with optional columns from mdata.obs joined.\n",
    "    \"\"\"\n",
    "    fs = model.get_factor_scores(as_df=True)\n",
    "    fs = fs.rename(columns={c: f\"Factor {i+1}\" for i, c in enumerate(fs.columns) if str(c).startswith(\"factor_\")})\n",
    "    if obs_keys:\n",
    "        fs = fs.join(mdata.obs[obs_keys])\n",
    "    if verbosity:\n",
    "        cols_show = [c for c in fs.columns if c.startswith(\"Factor \")][:3]\n",
    "        print(\"Scores columns:\", \", \".join(cols_show), \"...\")\n",
    "        if obs_keys:\n",
    "            print(\"Joined obs:\", \", \".join(obs_keys))\n",
    "    return fs\n",
    "\n",
    "def muvi_kruskal_info(scores_df: pd.DataFrame, group_col: str,\n",
    "                      factors: Optional[Sequence[str]] = None,\n",
    "                      bonferroni: bool = True, verbosity: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Kruskal Wallis p-values per factor across categories in group_col.\n",
    "    \"\"\"\n",
    "    from scipy.stats import kruskal\n",
    "    if factors is None:\n",
    "        factors = [c for c in scores_df.columns if str(c).startswith(\"Factor \")]\n",
    "    groups = scores_df[group_col].dropna().unique().tolist()\n",
    "\n",
    "    rows = []\n",
    "    for f in factors:\n",
    "        samples = [scores_df.loc[scores_df[group_col] == g, f].values for g in groups]\n",
    "        _, p = kruskal(*samples)\n",
    "        if bonferroni:\n",
    "            p = p * len(factors)\n",
    "            p = min(p, 1.0)\n",
    "        rows.append({\"Factor\": f, \"pvalue\": p})\n",
    "    out = pd.DataFrame(rows).sort_values(\"pvalue\")\n",
    "    if verbosity:\n",
    "        print(out.to_string(index=False))\n",
    "    return out\n",
    "\n",
    "def muvi_kendall_info(scores_df: pd.DataFrame, ordinal_col: str,\n",
    "                      factors: Optional[Sequence[str]] = None,\n",
    "                      bonferroni: bool = True, verbosity: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Kendall tau p-values vs an ordinal encoding of ordinal_col.\n",
    "    \"\"\"\n",
    "    from scipy.stats import kendalltau\n",
    "    if factors is None:\n",
    "        factors = [c for c in scores_df.columns if str(c).startswith(\"Factor \")]\n",
    "    codes = pd.Categorical(scores_df[ordinal_col]).codes\n",
    "    rows = []\n",
    "    for f in factors:\n",
    "        _, p = kendalltau(scores_df[f], codes)\n",
    "        if bonferroni:\n",
    "            p = p * len(factors)\n",
    "            p = min(p, 1.0)\n",
    "        rows.append({\"Factor\": f, \"pvalue\": p})\n",
    "    out = pd.DataFrame(rows).sort_values(\"pvalue\")\n",
    "    if verbosity:\n",
    "        print(out.to_string(index=False))\n",
    "    return out\n",
    "\n",
    "def muvi_violin_plot(scores_df: pd.DataFrame, factor: str, group_col: str,\n",
    "                     palette: Optional[List[str]] = None, pvalue: Optional[float] = None,\n",
    "                     save_path: Optional[str] = None,\n",
    "                     width: float = 4.5, height: float = 4.5, dpi: int = 300):\n",
    "    \"\"\"\n",
    "    Violin plot for one factor across categories in group_col.\n",
    "    \"\"\"\n",
    "    p = (\n",
    "        ggplot(scores_df, aes(y=factor, x=group_col, fill=group_col))\n",
    "        + geom_violin(style=\"right\", scale=\"width\", width=1.25)\n",
    "        + theme_classic()\n",
    "        + coord_flip()\n",
    "        + guides(fill=False)\n",
    "        + labs(title=f\"{factor}\" + (f\" adjusted p = {np.round(pvalue, 5)}\" if pvalue is not None else \"\"), x=group_col, y=factor)\n",
    "    )\n",
    "    if palette is not None:\n",
    "        p = p + scale_fill_manual(values=palette)\n",
    "    _ggsave_if(p, save_path, width, height, dpi)\n",
    "    return p\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6) Confidence ellipses for two factors by group\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def _cov_ellipse_points(cov: np.ndarray, center: np.ndarray, nstd: float = 2.0, num: int = 100) -> pd.DataFrame:\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "    order = eigvals.argsort()[::-1]\n",
    "    eigvals, eigvecs = eigvals[order], eigvecs[:, order]\n",
    "    transform = eigvecs @ np.diag(nstd * np.sqrt(eigvals))\n",
    "    t = np.linspace(0, 2*np.pi, num)\n",
    "    circle = np.column_stack([np.cos(t), np.sin(t)])\n",
    "    ellipse = circle @ transform.T\n",
    "    ellipse += center\n",
    "    return pd.DataFrame({\"x\": ellipse[:, 0], \"y\": ellipse[:, 1]})\n",
    "\n",
    "def muvi_confidence_ellipses_info(scores_df: pd.DataFrame, x_factor: str, y_factor: str,\n",
    "                                  group_col: str, nstd: float = 2.0, verbosity: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return ellipse points for each group level.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for g in scores_df[group_col].dropna().unique():\n",
    "        sub = scores_df[scores_df[group_col] == g]\n",
    "        x = sub[x_factor].to_numpy()\n",
    "        y = sub[y_factor].to_numpy()\n",
    "        center = np.array([np.nanmean(x), np.nanmean(y)])\n",
    "        cov = np.cov(np.vstack([x, y]))\n",
    "        ell = _cov_ellipse_points(cov, center, nstd=nstd)\n",
    "        ell[group_col] = g\n",
    "        out.append(ell)\n",
    "    df = pd.concat(out, ignore_index=True)\n",
    "    if verbosity:\n",
    "        print(df.head().to_string(index=False))\n",
    "    return df\n",
    "\n",
    "def muvi_confidence_ellipses_plot(scores_df: pd.DataFrame, ellipses_df: pd.DataFrame,\n",
    "                                  x_factor: str, y_factor: str, group_col: str,\n",
    "                                  palette: Optional[List[str]] = None,\n",
    "                                  save_path: Optional[str] = None,\n",
    "                                  width: float = 4.5, height: float = 4.5, dpi: int = 300):\n",
    "    \"\"\"\n",
    "    Plot confidence ellipses only. Returns ggplot.\n",
    "    \"\"\"\n",
    "    p = (\n",
    "        ggplot(scores_df, aes(x=x_factor, y=y_factor, color=group_col))\n",
    "        + geom_path(ellipses_df, aes(x=\"x\", y=\"y\", group=group_col, color=group_col), size = 3)\n",
    "        + theme_classic()\n",
    "        + ggtitle(\"Confidence ellipses by group\")\n",
    "        + coord_equal()\n",
    "    )\n",
    "    if palette is not None:\n",
    "        p = p + scale_fill_manual(values=palette)\n",
    "    _ggsave_if(p, save_path, width, height, dpi)\n",
    "    return p\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7) Export top features by view or by class\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def muvi_top_features_by_view_info(variable_loadings: pd.DataFrame,\n",
    "                                   factors: Sequence[str], top_per_view: int = 5,\n",
    "                                   by_abs: bool = True, verbosity: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a tidy table with top features per view across selected factors.\n",
    "    Columns: Variable, View, Weight, Factor\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for f in factors:\n",
    "        df = variable_loadings[[\"variable\", \"view\", f]].copy()\n",
    "        df[\"score\"] = df[f].abs() if by_abs else df[f]\n",
    "        top = df.sort_values(\"score\", ascending=False).groupby(\"view\").head(top_per_view)\n",
    "        top = top.drop(columns=\"score\").rename(columns={f: \"Weight\", \"view\": \"View\", \"variable\": \"Variable\"})\n",
    "        top[\"Factor\"] = f\n",
    "        rows.append(top)\n",
    "    out = pd.concat(rows, ignore_index=True)\n",
    "    # drop duplicates while keeping first\n",
    "    out = out.sort_values(by=\"Weight\", key=lambda x: x.abs(), ascending=False).drop_duplicates(subset=[\"Variable\", \"View\"])\n",
    "    # keep final number per view\n",
    "    out = out.groupby(\"View\", group_keys=False).head(top_per_view)\n",
    "    if verbosity:\n",
    "        print(out.head().to_string(index=False))\n",
    "    return out\n",
    "\n",
    "def muvi_top_features_by_class_info(variable_loadings: pd.DataFrame,\n",
    "                                    types_map: Dict[str, str],\n",
    "                                    factors: Sequence[str], top_per_class: int = 5,\n",
    "                                    by_abs: bool = True, verbosity: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    types_map: dict feature_name -> class label\n",
    "    Returns tidy table with Variable, View, Feature type, Weight, Factor\n",
    "    \"\"\"\n",
    "    df = variable_loadings.copy()\n",
    "    df[\"Feature type\"] = df[\"variable\"].map(types_map).fillna(\"NA\")\n",
    "\n",
    "    rows = []\n",
    "    for f in factors:\n",
    "        tmp = df[[\"variable\", \"view\", \"Feature type\", f]].copy()\n",
    "        tmp[\"score\"] = tmp[f].abs() if by_abs else tmp[f]\n",
    "        top = tmp.sort_values(\"score\", ascending=False).groupby(\"Feature type\").head(top_per_class)\n",
    "        top = top.drop(columns=\"score\").rename(columns={f: \"Weight\", \"view\": \"View\", \"variable\": \"Variable\"})\n",
    "        top[\"Factor\"] = f\n",
    "        rows.append(top)\n",
    "    out = pd.concat(rows, ignore_index=True)\n",
    "    out = out.sort_values(by=\"Weight\", key=lambda x: x.abs(), ascending=False).drop_duplicates(subset=[\"Variable\", \"View\"])\n",
    "    out = out.groupby(\"Feature type\", group_keys=False).head(top_per_class)\n",
    "    if verbosity:\n",
    "        print(out.head().to_string(index=False))\n",
    "    return out\n",
    "\n",
    "def muvi_build_selected_anndata(mdata, selection_df: pd.DataFrame,\n",
    "                                obs_anchor_view: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    Build a single-view AnnData matrix from selected features listed in selection_df\n",
    "    which must have columns ['Variable', 'View'].\n",
    "    \"\"\"\n",
    "    import muon as mu\n",
    "    assert set([\"Variable\", \"View\"]).issubset(selection_df.columns)\n",
    "    if obs_anchor_view is None:\n",
    "        obs_anchor_view = list(mdata.mod.keys())[0]\n",
    "    def _col(view, var):\n",
    "        return mdata[view].X[:, mdata[view].var_names == var]\n",
    "    X = np.hstack([_col(r[\"View\"], r[\"Variable\"]) for _, r in selection_df.iterrows()])\n",
    "    ad = mu.AnnData(X)\n",
    "    ad.obs = mdata[obs_anchor_view].obs.copy()\n",
    "    ad.var = selection_df.reset_index(drop=True).copy()\n",
    "    return ad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Minimal usage examples\n",
    "# =============================================================================\n",
    "# Assuming: model (trained MuVI) and features (MuData)\n",
    "\n",
    "# 1) Reconstruction R2 per view\n",
    "recon = muvi_reconstruction_info(model, mdata_processed, verbosity=1)\n",
    "p1 = muvi_reconstruction_plot(recon[\"by_view\"], title=\"Reconstruction R2 by view\")\n",
    "p1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Variance explained by factors per view with marginal sums\n",
    "v_by_view = muvi_variance_by_view_info(model, verbosity=0)\n",
    "p2 = muvi_variance_by_view_plot(v_by_view, subtitle=f\"Macro-R2: {np.round(recon['macro']['R2'], 3)}\")\n",
    "p2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Feature class vs factor variance explained\n",
    "# Example feature classes\n",
    "all_vars = mdata_processed.var_names.tolist()\n",
    "\n",
    "feature_type_map = {\n",
    "    \"Pathway 1\": [v for v in all_vars if any(f\"ft_{i}\" in v for i in [0, 1, 2])],\n",
    "    \"Pathway 2\": [v for v in all_vars if any(f\"ft_{i}\" in v for i in [3, 4])],\n",
    "    \"Pathway 3\": [v for v in all_vars if not any(f\"ft_{i}\" in v for i in range(5))]\n",
    "}\n",
    "\n",
    "# Run analysis\n",
    "v_by_class = muvi_featureclass_variance_info(\n",
    "    model,\n",
    "    mdata_processed,\n",
    "    feature_type_map=feature_type_map,\n",
    "    aggregator=\"median\",\n",
    "    verbosity=1\n",
    ")\n",
    "\n",
    "# Plot\n",
    "p3 = muvi_featureclass_variance_plot(v_by_class)\n",
    "p3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Variable loadings and top features for a factor\n",
    "var_load = muvi_variable_loadings_info(model, mdata_processed, verbosity=0)\n",
    "p4 = muvi_plot_top_loadings_heatmap(var_load, factor=\"Factor 1\", top_n=30)\n",
    "p4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Selected features across factors\n",
    "picked = [(\"Cell Type 1_gene_1\", \"Cell Type 1\"), \n",
    "          (\"Cell Type 2_gene_1\", \"Cell Type 2\"),\n",
    "          (\"Cell Type 3_gene_3\", \"Cell Type 3\"),]\n",
    "picked_long = muvi_selected_features_info(var_load, picked, verbosity=0)\n",
    "p5 = muvi_selected_features_plot(picked_long)\n",
    "p5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Scores with clinical covariates and tests\n",
    "clin_variables = [\"Cell Type 1:batch\", \"exposure\"]\n",
    "scores = muvi_factor_scores_info(model, mdata_processed, obs_keys=clin_variables, verbosity=0)\n",
    "\n",
    "for var in clin_variables:\n",
    "    print(f\"Kruskal-Wallis test for {var}\")\n",
    "    kw = muvi_kruskal_info(scores, group_col=var, verbosity=1)\n",
    "    print(f\"Kendall tau test for {var}\") # For ordinal variables\n",
    "    muvi_kendall_info(scores, ordinal_col=var, verbosity=1)\n",
    "    p6 = muvi_violin_plot(scores, factor=\"Factor 2\", group_col=var, pvalue=float(kw[kw.Factor==\"Factor 2\"][\"pvalue\"]))\n",
    "    p6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Confidence ellipses for two factors by \n",
    "ell = muvi_confidence_ellipses_info(scores, x_factor=\"Factor 1\", y_factor=\"Factor 2\", group_col=\"exposure\", \n",
    "                                    nstd=2, verbosity=1)\n",
    "p7 = muvi_confidence_ellipses_plot(scores, ell, x_factor=\"Factor 1\", y_factor=\"Factor 2\", group_col=\"exposure\")\n",
    "p7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Export top features\n",
    "top_by_view = muvi_top_features_by_view_info(var_load, factors=[\"Factor 1\", \"Factor 2\"], \n",
    "                                             top_per_view=2, verbosity=0)\n",
    "top_ad = muvi_build_selected_anndata(mdata_processed, top_by_view.rename(columns={\"View\": \"View\"}))\n",
    "top_ad.write(\"top_features_multi_pT.h5ad\")\n",
    "top_by_view.to_csv(\"top_features_multi_pT.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muvicell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
